{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-16T01:13:50.356589Z","iopub.execute_input":"2023-08-16T01:13:50.356979Z","iopub.status.idle":"2023-08-16T01:13:50.367978Z","shell.execute_reply.started":"2023-08-16T01:13:50.356929Z","shell.execute_reply":"2023-08-16T01:13:50.366652Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/dpl-disaster-tweets/sample_submission.csv\n/kaggle/input/dpl-disaster-tweets/train.csv\n/kaggle/input/dpl-disaster-tweets/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"%env WANDB_DISABLED=True","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:13:50.369357Z","iopub.execute_input":"2023-08-16T01:13:50.369695Z","iopub.status.idle":"2023-08-16T01:13:50.376990Z","shell.execute_reply.started":"2023-08-16T01:13:50.369658Z","shell.execute_reply":"2023-08-16T01:13:50.376131Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"env: WANDB_DISABLED=True\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndataset = pd.read_csv('/kaggle/input/dpl-disaster-tweets/train.csv')\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:42.582197Z","iopub.execute_input":"2023-08-16T01:20:42.582485Z","iopub.status.idle":"2023-08-16T01:20:42.629556Z","shell.execute_reply.started":"2023-08-16T01:20:42.582453Z","shell.execute_reply":"2023-08-16T01:20:42.628602Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = dataset.drop(['keyword', 'location'], axis=1)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:44.020386Z","iopub.execute_input":"2023-08-16T01:20:44.020713Z","iopub.status.idle":"2023-08-16T01:20:44.038569Z","shell.execute_reply.started":"2023-08-16T01:20:44.020672Z","shell.execute_reply":"2023-08-16T01:20:44.037659Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"   id                                               text  target\n0   1  Our Deeds are the Reason of this #earthquake M...       1\n1   4             Forest fire near La Ronge Sask. Canada       1\n2   5  All residents asked to 'shelter in place' are ...       1\n3   6  13,000 people receive #wildfires evacuation or...       1\n4   7  Just got sent this photo from Ruby #Alaska as ...       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:44.311897Z","iopub.execute_input":"2023-08-16T01:20:44.312180Z","iopub.status.idle":"2023-08-16T01:20:44.324450Z","shell.execute_reply.started":"2023-08-16T01:20:44.312149Z","shell.execute_reply":"2023-08-16T01:20:44.323572Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"id        0\ntext      0\ntarget    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"len(df[df['target']==1])","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:45.702441Z","iopub.execute_input":"2023-08-16T01:20:45.702812Z","iopub.status.idle":"2023-08-16T01:20:45.713851Z","shell.execute_reply.started":"2023-08-16T01:20:45.702777Z","shell.execute_reply":"2023-08-16T01:20:45.712681Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"3271"},"metadata":{}}]},{"cell_type":"code","source":"len(df[df['target']==0])","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:47.119803Z","iopub.execute_input":"2023-08-16T01:20:47.120090Z","iopub.status.idle":"2023-08-16T01:20:47.134848Z","shell.execute_reply.started":"2023-08-16T01:20:47.120061Z","shell.execute_reply":"2023-08-16T01:20:47.133747Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"4342"},"metadata":{}}]},{"cell_type":"code","source":"df['text']=df['text'].apply(lambda x: x.lower())","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:48.500862Z","iopub.execute_input":"2023-08-16T01:20:48.501150Z","iopub.status.idle":"2023-08-16T01:20:48.517006Z","shell.execute_reply.started":"2023-08-16T01:20:48.501119Z","shell.execute_reply":"2023-08-16T01:20:48.515835Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"df['text']=df['text'].apply(lambda x: x.replace(\"#\", \"\"))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:48.789538Z","iopub.execute_input":"2023-08-16T01:20:48.789893Z","iopub.status.idle":"2023-08-16T01:20:48.806732Z","shell.execute_reply.started":"2023-08-16T01:20:48.789858Z","shell.execute_reply":"2023-08-16T01:20:48.804957Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"import string \nprint(string.punctuation)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:49.405257Z","iopub.execute_input":"2023-08-16T01:20:49.405558Z","iopub.status.idle":"2023-08-16T01:20:49.414767Z","shell.execute_reply.started":"2023-08-16T01:20:49.405524Z","shell.execute_reply":"2023-08-16T01:20:49.413888Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n","output_type":"stream"}]},{"cell_type":"code","source":"str.maketrans(dict.fromkeys(string.punctuation))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:50.618101Z","iopub.execute_input":"2023-08-16T01:20:50.618395Z","iopub.status.idle":"2023-08-16T01:20:50.628599Z","shell.execute_reply.started":"2023-08-16T01:20:50.618362Z","shell.execute_reply":"2023-08-16T01:20:50.627641Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"{33: None,\n 34: None,\n 35: None,\n 36: None,\n 37: None,\n 38: None,\n 39: None,\n 40: None,\n 41: None,\n 42: None,\n 43: None,\n 44: None,\n 45: None,\n 46: None,\n 47: None,\n 58: None,\n 59: None,\n 60: None,\n 61: None,\n 62: None,\n 63: None,\n 64: None,\n 91: None,\n 92: None,\n 93: None,\n 94: None,\n 95: None,\n 96: None,\n 123: None,\n 124: None,\n 125: None,\n 126: None}"},"metadata":{}}]},{"cell_type":"code","source":"df['text']=df['text'].apply(lambda x: x.translate(str.maketrans(dict.fromkeys(string.punctuation))))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:52.104500Z","iopub.execute_input":"2023-08-16T01:20:52.104840Z","iopub.status.idle":"2023-08-16T01:20:52.176837Z","shell.execute_reply.started":"2023-08-16T01:20:52.104807Z","shell.execute_reply":"2023-08-16T01:20:52.175941Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"df['text'][5]","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:52.344367Z","iopub.execute_input":"2023-08-16T01:20:52.345202Z","iopub.status.idle":"2023-08-16T01:20:52.358469Z","shell.execute_reply.started":"2023-08-16T01:20:52.345164Z","shell.execute_reply":"2023-08-16T01:20:52.357326Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"'rockyfire update  california hwy 20 closed in both directions due to lake county fire  cafire wildfires'"},"metadata":{}}]},{"cell_type":"code","source":"df['text']=df['text'].apply(lambda x: x.translate(str.maketrans('', '', string.digits)))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:53.562881Z","iopub.execute_input":"2023-08-16T01:20:53.563168Z","iopub.status.idle":"2023-08-16T01:20:53.608318Z","shell.execute_reply.started":"2023-08-16T01:20:53.563138Z","shell.execute_reply":"2023-08-16T01:20:53.605174Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"df['text'][5]","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:53.767736Z","iopub.execute_input":"2023-08-16T01:20:53.768012Z","iopub.status.idle":"2023-08-16T01:20:53.778468Z","shell.execute_reply.started":"2023-08-16T01:20:53.767984Z","shell.execute_reply":"2023-08-16T01:20:53.777684Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"'rockyfire update  california hwy  closed in both directions due to lake county fire  cafire wildfires'"},"metadata":{}}]},{"cell_type":"code","source":"for index, row in df.iterrows():\n    text=[]\n    for word in row['text'].split():\n        if \"http\" not in word:\n            text.append(word)\n    row['text']=\" \".join(text)\n    #print(row['text'])\n    df['text'][index]=row['text']\n        ","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:55.003808Z","iopub.execute_input":"2023-08-16T01:20:55.004089Z","iopub.status.idle":"2023-08-16T01:20:59.116635Z","shell.execute_reply.started":"2023-08-16T01:20:55.004059Z","shell.execute_reply":"2023-08-16T01:20:59.115363Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"df['text'][7612]","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:59.118233Z","iopub.execute_input":"2023-08-16T01:20:59.118516Z","iopub.status.idle":"2023-08-16T01:20:59.135141Z","shell.execute_reply.started":"2023-08-16T01:20:59.118476Z","shell.execute_reply":"2023-08-16T01:20:59.134228Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"'the latest more homes razed by northern california wildfire abc news'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:13:54.195465Z","iopub.execute_input":"2023-08-16T01:13:54.196494Z","iopub.status.idle":"2023-08-16T01:14:03.170071Z","shell.execute_reply.started":"2023-08-16T01:13:54.196454Z","shell.execute_reply":"2023-08-16T01:14:03.168747Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.5.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (21.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.46)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.8.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.8.28)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.5.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.10.0.2)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import Dataset\nfrom transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, default_data_collator, Trainer, set_seed\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:21:00.234980Z","iopub.execute_input":"2023-08-16T01:21:00.235273Z","iopub.status.idle":"2023-08-16T01:21:00.245339Z","shell.execute_reply.started":"2023-08-16T01:21:00.235240Z","shell.execute_reply":"2023-08-16T01:21:00.244324Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:21:00.482044Z","iopub.execute_input":"2023-08-16T01:21:00.482337Z","iopub.status.idle":"2023-08-16T01:21:00.490026Z","shell.execute_reply.started":"2023-08-16T01:21:00.482305Z","shell.execute_reply":"2023-08-16T01:21:00.488121Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom transformers import BertTokenizer, BertForSequenceClassification\n\n# Khởi tạo tokenizer và mô hình\ntokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-large-uncased')\n\n# Xây dựng lớp mới\nnew_classifier = nn.Sequential(\n    nn.Linear(1024, 512),\n    nn.ReLU(),\n    nn.Dropout(0.5),\n    nn.Linear(512, model.classifier.out_features)  # Giả sử bạn muốn giữ nguyên số lượng lớp đầu ra\n)\n\n# Gán lớp mới vào mô hình\nmodel.classifier = new_classifier\n\n# Chuyển mô hình sang GPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:20:08.265462Z","iopub.execute_input":"2023-08-16T01:20:08.265839Z","iopub.status.idle":"2023-08-16T01:20:26.155240Z","shell.execute_reply.started":"2023-08-16T01:20:08.265800Z","shell.execute_reply":"2023-08-16T01:20:26.154261Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n      (position_embeddings): Embedding(512, 1024)\n      (token_type_embeddings): Embedding(2, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (12): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (13): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (14): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (15): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (16): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (17): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (18): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (19): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (20): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (21): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (22): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (23): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Sequential(\n    (0): Linear(in_features=1024, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=512, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"maxx, minn = 0, 1000000\nfor index, row in df.iterrows():\n    if len(row['text'].split())>maxx:\n        maxx=len(row['text'].split())\n    if len(row['text'].split())<minn:\n        minn=len(row['text'].split())\nmaxx, minn","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:21:09.134877Z","iopub.execute_input":"2023-08-16T01:21:09.135164Z","iopub.status.idle":"2023-08-16T01:21:09.619293Z","shell.execute_reply.started":"2023-08-16T01:21:09.135134Z","shell.execute_reply":"2023-08-16T01:21:09.618533Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"(31, 1)"},"metadata":{}}]},{"cell_type":"code","source":"max_length=64\ndf['input_ids']=df['text'].apply(lambda x: tokenizer(x, max_length=max_length, padding='max_length')['input_ids'])\ndf.head(n=10)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:21:12.121502Z","iopub.execute_input":"2023-08-16T01:21:12.122176Z","iopub.status.idle":"2023-08-16T01:21:17.810222Z","shell.execute_reply.started":"2023-08-16T01:21:12.122140Z","shell.execute_reply":"2023-08-16T01:21:17.809188Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"   id                                               text  target  \\\n0   1  our deeds are the reason of this earthquake ma...       1   \n1   4              forest fire near la ronge sask canada       1   \n2   5  all residents asked to shelter in place are be...       1   \n3   6  people receive wildfires evacuation orders in ...       1   \n4   7  just got sent this photo from ruby alaska as s...       1   \n5   8  rockyfire update california hwy closed in both...       1   \n6  10  flood disaster heavy rain causes flash floodin...       1   \n7  13  im on top of the hill and i can see a fire in ...       1   \n8  14  theres an emergency evacuation happening now i...       1   \n9  15   im afraid that the tornado is coming to our area       1   \n\n                                           input_ids  \n0  [101, 2256, 15616, 2024, 1996, 3114, 1997, 202...  \n1  [101, 3224, 2543, 2379, 2474, 6902, 3351, 2187...  \n2  [101, 2035, 3901, 2356, 2000, 7713, 1999, 2173...  \n3  [101, 2111, 4374, 3748, 26332, 13982, 4449, 19...  \n4  [101, 2074, 2288, 2741, 2023, 6302, 2013, 1009...  \n5  [101, 6857, 10273, 10651, 2662, 1044, 18418, 2...  \n6  [101, 7186, 7071, 3082, 4542, 5320, 5956, 9451...  \n7  [101, 10047, 2006, 2327, 1997, 1996, 2940, 199...  \n8  [101, 2045, 2015, 2019, 5057, 13982, 6230, 208...  \n9  [101, 10047, 4452, 2008, 1996, 11352, 2003, 27...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>target</th>\n      <th>input_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>our deeds are the reason of this earthquake ma...</td>\n      <td>1</td>\n      <td>[101, 2256, 15616, 2024, 1996, 3114, 1997, 202...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>forest fire near la ronge sask canada</td>\n      <td>1</td>\n      <td>[101, 3224, 2543, 2379, 2474, 6902, 3351, 2187...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>all residents asked to shelter in place are be...</td>\n      <td>1</td>\n      <td>[101, 2035, 3901, 2356, 2000, 7713, 1999, 2173...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>people receive wildfires evacuation orders in ...</td>\n      <td>1</td>\n      <td>[101, 2111, 4374, 3748, 26332, 13982, 4449, 19...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>just got sent this photo from ruby alaska as s...</td>\n      <td>1</td>\n      <td>[101, 2074, 2288, 2741, 2023, 6302, 2013, 1009...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>8</td>\n      <td>rockyfire update california hwy closed in both...</td>\n      <td>1</td>\n      <td>[101, 6857, 10273, 10651, 2662, 1044, 18418, 2...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10</td>\n      <td>flood disaster heavy rain causes flash floodin...</td>\n      <td>1</td>\n      <td>[101, 7186, 7071, 3082, 4542, 5320, 5956, 9451...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>13</td>\n      <td>im on top of the hill and i can see a fire in ...</td>\n      <td>1</td>\n      <td>[101, 10047, 2006, 2327, 1997, 1996, 2940, 199...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>14</td>\n      <td>theres an emergency evacuation happening now i...</td>\n      <td>1</td>\n      <td>[101, 2045, 2015, 2019, 5057, 13982, 6230, 208...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>15</td>\n      <td>im afraid that the tornado is coming to our area</td>\n      <td>1</td>\n      <td>[101, 10047, 4452, 2008, 1996, 11352, 2003, 27...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.rename(columns={'target':'labels'}, inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:21:17.814908Z","iopub.execute_input":"2023-08-16T01:21:17.815153Z","iopub.status.idle":"2023-08-16T01:21:17.830383Z","shell.execute_reply.started":"2023-08-16T01:21:17.815123Z","shell.execute_reply":"2023-08-16T01:21:17.829596Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"   id                                               text  labels  \\\n0   1  our deeds are the reason of this earthquake ma...       1   \n1   4              forest fire near la ronge sask canada       1   \n2   5  all residents asked to shelter in place are be...       1   \n3   6  people receive wildfires evacuation orders in ...       1   \n4   7  just got sent this photo from ruby alaska as s...       1   \n\n                                           input_ids  \n0  [101, 2256, 15616, 2024, 1996, 3114, 1997, 202...  \n1  [101, 3224, 2543, 2379, 2474, 6902, 3351, 2187...  \n2  [101, 2035, 3901, 2356, 2000, 7713, 1999, 2173...  \n3  [101, 2111, 4374, 3748, 26332, 13982, 4449, 19...  \n4  [101, 2074, 2288, 2741, 2023, 6302, 2013, 1009...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>labels</th>\n      <th>input_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>our deeds are the reason of this earthquake ma...</td>\n      <td>1</td>\n      <td>[101, 2256, 15616, 2024, 1996, 3114, 1997, 202...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>forest fire near la ronge sask canada</td>\n      <td>1</td>\n      <td>[101, 3224, 2543, 2379, 2474, 6902, 3351, 2187...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>all residents asked to shelter in place are be...</td>\n      <td>1</td>\n      <td>[101, 2035, 3901, 2356, 2000, 7713, 1999, 2173...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>people receive wildfires evacuation orders in ...</td>\n      <td>1</td>\n      <td>[101, 2111, 4374, 3748, 26332, 13982, 4449, 19...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>just got sent this photo from ruby alaska as s...</td>\n      <td>1</td>\n      <td>[101, 2074, 2288, 2741, 2023, 6302, 2013, 1009...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df[['input_ids', 'labels']]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:21:17.832122Z","iopub.execute_input":"2023-08-16T01:21:17.832570Z","iopub.status.idle":"2023-08-16T01:21:17.862571Z","shell.execute_reply.started":"2023-08-16T01:21:17.832532Z","shell.execute_reply":"2023-08-16T01:21:17.861654Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"                                           input_ids  labels\n0  [101, 2256, 15616, 2024, 1996, 3114, 1997, 202...       1\n1  [101, 3224, 2543, 2379, 2474, 6902, 3351, 2187...       1\n2  [101, 2035, 3901, 2356, 2000, 7713, 1999, 2173...       1\n3  [101, 2111, 4374, 3748, 26332, 13982, 4449, 19...       1\n4  [101, 2074, 2288, 2741, 2023, 6302, 2013, 1009...       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[101, 2256, 15616, 2024, 1996, 3114, 1997, 202...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[101, 3224, 2543, 2379, 2474, 6902, 3351, 2187...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[101, 2035, 3901, 2356, 2000, 7713, 1999, 2173...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[101, 2111, 4374, 3748, 26332, 13982, 4449, 19...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[101, 2074, 2288, 2741, 2023, 6302, 2013, 1009...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df = df[:-int(len(df)*0.01)].reset_index(drop=True)\ntest_df = df[-int(len(df)*0.01):].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:21:17.866758Z","iopub.execute_input":"2023-08-16T01:21:17.867134Z","iopub.status.idle":"2023-08-16T01:21:17.875383Z","shell.execute_reply.started":"2023-08-16T01:21:17.867104Z","shell.execute_reply":"2023-08-16T01:21:17.874423Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"len(train_df), len(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:21:17.877188Z","iopub.execute_input":"2023-08-16T01:21:17.877482Z","iopub.status.idle":"2023-08-16T01:21:17.890869Z","shell.execute_reply.started":"2023-08-16T01:21:17.877446Z","shell.execute_reply":"2023-08-16T01:21:17.889672Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"(7537, 76)"},"metadata":{}}]},{"cell_type":"code","source":"train_ds = Dataset.from_pandas(train_df)\ntest_ds = Dataset.from_pandas(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:21:17.892946Z","iopub.execute_input":"2023-08-16T01:21:17.893323Z","iopub.status.idle":"2023-08-16T01:21:17.950176Z","shell.execute_reply.started":"2023-08-16T01:21:17.893279Z","shell.execute_reply":"2023-08-16T01:21:17.949126Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:21:17.956201Z","iopub.execute_input":"2023-08-16T01:21:17.956647Z","iopub.status.idle":"2023-08-16T01:21:17.969497Z","shell.execute_reply.started":"2023-08-16T01:21:17.956594Z","shell.execute_reply":"2023-08-16T01:21:17.968435Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'labels'],\n    num_rows: 7537\n})"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 16\n\nargs = TrainingArguments(\n    'nlp-getting-started',\n    evaluation_strategy = 'epoch',\n    save_strategy = 'epoch',\n    learning_rate=3e-5,\n    gradient_accumulation_steps=8,\n    num_train_epochs=1,\n    warmup_ratio=0.1,\n    weight_decay=0.01,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n)\n\ndata_collator = default_data_collator\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_ds,\n    eval_dataset=test_ds,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:21:48.808895Z","iopub.execute_input":"2023-08-16T01:21:48.809180Z","iopub.status.idle":"2023-08-16T01:21:49.394768Z","shell.execute_reply.started":"2023-08-16T01:21:48.809149Z","shell.execute_reply":"2023-08-16T01:21:49.393480Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stderr","text":"Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:21:51.418798Z","iopub.execute_input":"2023-08-16T01:21:51.419087Z","iopub.status.idle":"2023-08-16T01:25:12.228771Z","shell.execute_reply.started":"2023-08-16T01:21:51.419057Z","shell.execute_reply":"2023-08-16T01:25:12.227895Z"},"trusted":true},"execution_count":69,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='59' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [59/59 03:16, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Runtime</th>\n      <th>Samples Per Second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.458532</td>\n      <td>0.548800</td>\n      <td>138.496000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=59, training_loss=0.6511969485525357, metrics={'train_runtime': 200.2771, 'train_samples_per_second': 0.295, 'total_flos': 971492183200512.0, 'epoch': 1.0, 'init_mem_cpu_alloc_delta': 8192, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 1687552, 'train_mem_gpu_alloc_delta': 2686966272, 'train_mem_cpu_peaked_delta': 0, 'train_mem_gpu_peaked_delta': 2030453248})"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom datasets import load_metric\n\nmetric = load_metric(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:25:38.549909Z","iopub.execute_input":"2023-08-16T01:25:38.550199Z","iopub.status.idle":"2023-08-16T01:25:38.984808Z","shell.execute_reply.started":"2023-08-16T01:25:38.550161Z","shell.execute_reply":"2023-08-16T01:25:38.983222Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_ds,\n    eval_dataset=test_ds,\n    compute_metrics=compute_metrics,\n)\ntrainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:25:41.955004Z","iopub.execute_input":"2023-08-16T01:25:41.955292Z","iopub.status.idle":"2023-08-16T01:25:43.489656Z","shell.execute_reply.started":"2023-08-16T01:25:41.955260Z","shell.execute_reply":"2023-08-16T01:25:43.488811Z"},"trusted":true},"execution_count":73,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n        </style>\n      \n      <progress value='209' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:47]\n    </div>\n    "},"metadata":{}},{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.4585317373275757,\n 'eval_accuracy': 0.9210526315789473,\n 'eval_runtime': 0.6227,\n 'eval_samples_per_second': 122.04,\n 'init_mem_cpu_alloc_delta': 0,\n 'init_mem_gpu_alloc_delta': 0,\n 'init_mem_cpu_peaked_delta': 0,\n 'init_mem_gpu_peaked_delta': 0,\n 'eval_mem_cpu_alloc_delta': 0,\n 'eval_mem_gpu_alloc_delta': 0,\n 'eval_mem_cpu_peaked_delta': 0,\n 'eval_mem_gpu_peaked_delta': 46166016}"},"metadata":{}}]},{"cell_type":"code","source":"df_submission = pd.read_csv('/kaggle/input/dpl-disaster-tweets/test.csv')\ndf_submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:25:54.500753Z","iopub.execute_input":"2023-08-16T01:25:54.501038Z","iopub.status.idle":"2023-08-16T01:25:54.540779Z","shell.execute_reply.started":"2023-08-16T01:25:54.501008Z","shell.execute_reply":"2023-08-16T01:25:54.539552Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_submission['text']=df_submission['text'].apply(lambda x: x.lower())","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:25:56.006016Z","iopub.execute_input":"2023-08-16T01:25:56.006336Z","iopub.status.idle":"2023-08-16T01:25:56.018706Z","shell.execute_reply.started":"2023-08-16T01:25:56.006302Z","shell.execute_reply":"2023-08-16T01:25:56.017211Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"df_submission['text']=df_submission['text'].apply(lambda x: x.replace(\"#\", \"\"))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:25:56.714285Z","iopub.execute_input":"2023-08-16T01:25:56.714579Z","iopub.status.idle":"2023-08-16T01:25:56.726968Z","shell.execute_reply.started":"2023-08-16T01:25:56.714548Z","shell.execute_reply":"2023-08-16T01:25:56.726016Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"df_submission['text']=df_submission['text'].apply(lambda x: x.translate(str.maketrans(dict.fromkeys(string.punctuation))))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:25:58.256566Z","iopub.execute_input":"2023-08-16T01:25:58.257108Z","iopub.status.idle":"2023-08-16T01:25:58.292308Z","shell.execute_reply.started":"2023-08-16T01:25:58.257072Z","shell.execute_reply":"2023-08-16T01:25:58.291520Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"df_submission['text']=df_submission['text'].apply(lambda x: x.translate(str.maketrans('', '', string.digits)))","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:25:59.424795Z","iopub.execute_input":"2023-08-16T01:25:59.425084Z","iopub.status.idle":"2023-08-16T01:25:59.451842Z","shell.execute_reply.started":"2023-08-16T01:25:59.425055Z","shell.execute_reply":"2023-08-16T01:25:59.450678Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"for index, row in df_submission.iterrows():\n    text=[]\n    for word in row['text'].split():\n        if \"http\" not in word:\n            text.append(word)\n    row['text']=\" \".join(text)\n    #print(row['text'])\n    df_submission['text'][index]=row['text']","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:26:00.566173Z","iopub.execute_input":"2023-08-16T01:26:00.566452Z","iopub.status.idle":"2023-08-16T01:26:02.220851Z","shell.execute_reply.started":"2023-08-16T01:26:00.566421Z","shell.execute_reply":"2023-08-16T01:26:02.218998Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"df_submission['text'][89]","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:26:02.224989Z","iopub.execute_input":"2023-08-16T01:26:02.225532Z","iopub.status.idle":"2023-08-16T01:26:02.235310Z","shell.execute_reply.started":"2023-08-16T01:26:02.225488Z","shell.execute_reply":"2023-08-16T01:26:02.234045Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"'cop pulls drunk driver to safety seconds before his car is hit by train via viralspell'"},"metadata":{}}]},{"cell_type":"code","source":"df_submission['input_ids']=df_submission['text'].apply(lambda x: tokenizer(x, max_length=max_length, padding='max_length')['input_ids'])\ndf_submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:26:02.236303Z","iopub.execute_input":"2023-08-16T01:26:02.236514Z","iopub.status.idle":"2023-08-16T01:26:04.832413Z","shell.execute_reply.started":"2023-08-16T01:26:02.236489Z","shell.execute_reply":"2023-08-16T01:26:04.831647Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   0     NaN      NaN                 just happened a terrible car crash   \n1   2     NaN      NaN  heard about earthquake is different cities sta...   \n2   3     NaN      NaN  there is a forest fire at spot pond geese are ...   \n3   9     NaN      NaN              apocalypse lighting spokane wildfires   \n4  11     NaN      NaN         typhoon soudelor kills in china and taiwan   \n\n                                           input_ids  \n0  [101, 2074, 3047, 1037, 6659, 2482, 5823, 102,...  \n1  [101, 2657, 2055, 8372, 2003, 2367, 3655, 2994...  \n2  [101, 2045, 2003, 1037, 3224, 2543, 2012, 3962...  \n3  [101, 16976, 7497, 21878, 3748, 26332, 102, 0,...  \n4  [101, 15393, 2061, 12672, 10626, 8563, 1999, 2...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>input_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>just happened a terrible car crash</td>\n      <td>[101, 2074, 3047, 1037, 6659, 2482, 5823, 102,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>heard about earthquake is different cities sta...</td>\n      <td>[101, 2657, 2055, 8372, 2003, 2367, 3655, 2994...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond geese are ...</td>\n      <td>[101, 2045, 2003, 1037, 3224, 2543, 2012, 3962...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>apocalypse lighting spokane wildfires</td>\n      <td>[101, 16976, 7497, 21878, 3748, 26332, 102, 0,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>typhoon soudelor kills in china and taiwan</td>\n      <td>[101, 15393, 2061, 12672, 10626, 8563, 1999, 2...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_submission=df_submission[['input_ids']]\ndf_submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:26:04.834359Z","iopub.execute_input":"2023-08-16T01:26:04.836831Z","iopub.status.idle":"2023-08-16T01:26:04.860104Z","shell.execute_reply.started":"2023-08-16T01:26:04.836794Z","shell.execute_reply":"2023-08-16T01:26:04.858789Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"                                           input_ids\n0  [101, 2074, 3047, 1037, 6659, 2482, 5823, 102,...\n1  [101, 2657, 2055, 8372, 2003, 2367, 3655, 2994...\n2  [101, 2045, 2003, 1037, 3224, 2543, 2012, 3962...\n3  [101, 16976, 7497, 21878, 3748, 26332, 102, 0,...\n4  [101, 15393, 2061, 12672, 10626, 8563, 1999, 2...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[101, 2074, 3047, 1037, 6659, 2482, 5823, 102,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[101, 2657, 2055, 8372, 2003, 2367, 3655, 2994...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[101, 2045, 2003, 1037, 3224, 2543, 2012, 3962...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[101, 16976, 7497, 21878, 3748, 26332, 102, 0,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[101, 15393, 2061, 12672, 10626, 8563, 1999, 2...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"output_ds = Dataset.from_pandas(df_submission)\noutput_ds","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:26:06.747455Z","iopub.execute_input":"2023-08-16T01:26:06.747769Z","iopub.status.idle":"2023-08-16T01:26:06.781532Z","shell.execute_reply.started":"2023-08-16T01:26:06.747736Z","shell.execute_reply":"2023-08-16T01:26:06.780646Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids'],\n    num_rows: 3263\n})"},"metadata":{}}]},{"cell_type":"code","source":"outputs=trainer.predict(output_ds)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:26:06.991720Z","iopub.execute_input":"2023-08-16T01:26:06.992001Z","iopub.status.idle":"2023-08-16T01:26:30.919688Z","shell.execute_reply.started":"2023-08-16T01:26:06.991972Z","shell.execute_reply":"2023-08-16T01:26:30.918699Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"outputs.predictions.argmax(1)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:26:30.924543Z","iopub.execute_input":"2023-08-16T01:26:30.924864Z","iopub.status.idle":"2023-08-16T01:26:30.936807Z","shell.execute_reply.started":"2023-08-16T01:26:30.924829Z","shell.execute_reply":"2023-08-16T01:26:30.935726Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, ..., 0, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"sub = pd.read_csv('../input/dpl-disaster-tweets/sample_submission.csv')\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:26:46.513246Z","iopub.execute_input":"2023-08-16T01:26:46.513569Z","iopub.status.idle":"2023-08-16T01:26:46.536912Z","shell.execute_reply.started":"2023-08-16T01:26:46.513535Z","shell.execute_reply":"2023-08-16T01:26:46.535864Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"   id  target\n0   0       0\n1   2       0\n2   3       0\n3   9       0\n4  11       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sub['target'] = outputs.predictions.argmax(1)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:26:47.991213Z","iopub.execute_input":"2023-08-16T01:26:47.991492Z","iopub.status.idle":"2023-08-16T01:26:48.010101Z","shell.execute_reply.started":"2023-08-16T01:26:47.991460Z","shell.execute_reply":"2023-08-16T01:26:48.008751Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"   id  target\n0   0       0\n1   2       0\n2   3       0\n3   9       0\n4  11       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sub.to_csv('submission_final.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T01:26:48.172880Z","iopub.execute_input":"2023-08-16T01:26:48.173161Z","iopub.status.idle":"2023-08-16T01:26:48.189334Z","shell.execute_reply.started":"2023-08-16T01:26:48.173131Z","shell.execute_reply":"2023-08-16T01:26:48.188378Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}